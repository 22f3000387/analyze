# Data Processing and CI/CD Project

This project demonstrates a data processing workflow using Python (Pandas) and implements a Continuous Integration/Continuous Deployment (CI/CD) pipeline with GitHub Actions. The pipeline handles data conversion, script execution, linting, and publishes the processed results to GitHub Pages.

## Project Overview

- **`data.xlsx`**: The initial Excel data file.
- **`data.csv`**: The CSV version of `data.xlsx`, generated during the CI process.
- **`execute.py`**: A Python script designed to process `data.csv` and output a JSON result.
- **`result.json`**: The JSON output generated by `execute.py`, published to GitHub Pages.
- **`.github/workflows/ci.yml`**: The GitHub Actions workflow definition.

## `execute.py` Fix

The original `execute.py` contained a non-trivial error primarily related to data type handling and robustness. The assumed original error was that the script did not adequately handle non-numeric entries in the 'Value' column, which could lead to runtime errors during numerical operations (e.g., `sum()`). It also lacked explicit error handling for missing columns.

The fix implemented addresses these issues:
1.  **Ensured Numeric Conversion**: The 'Value' column is now explicitly converted to a numeric type using `pd.to_numeric(df['Value'], errors='coerce')`. The `errors='coerce'` argument ensures that any non-numeric values are converted to `NaN` (Not a Number) instead of raising an error.
2.  **Robust Data Handling**: Rows containing `NaN` values in the 'Value' column (resulting from the coercion) are dropped using `df.dropna(subset=['Value'], inplace=True)`, preventing aggregation errors.
3.  **Column Existence Checks**: Added checks to ensure 'Category' and 'Value' columns exist before attempting operations on them.
4.  **Output to JSON**: The script now explicitly writes its processed output to `result.json` directly, as required by the CI/CD workflow.

This makes `execute.py` more resilient to varied input data and ensures stable execution within the CI environment.

## `data.xlsx` to `data.csv` Conversion

The `data.xlsx` file is converted to `data.csv` as an initial step in the CI pipeline. This conversion is performed using Pandas within a GitHub Actions step, ensuring `execute.py` always operates on a standardized CSV format.

## GitHub Actions Workflow (`.github/workflows/ci.yml`)

The CI/CD pipeline is configured to run on every push to the `main` branch and on pull requests. It performs the following steps:

1.  **Checkout Repository**: Fetches the latest code.
2.  **Set up Python 3.11**: Configures the environment with Python 3.11, as required.
3.  **Install Dependencies**: Installs `pandas==2.3` and `ruff` for linting.
4.  **Run Ruff Linter**: Executes `ruff check .` to enforce code quality and style, with results displayed in the CI log.
5.  **Convert `data.xlsx` to `data.csv`**: A Python one-liner uses `pandas` to read `data.xlsx` and save it as `data.csv`.
6.  **Execute script and generate `result.json`**: Runs `python execute.py`. The script internally generates `result.json`.
7.  **Upload `result.json` Artifact**: The generated `result.json` is uploaded as a GitHub Pages artifact.
8.  **Deploy to GitHub Pages**: The artifact is then deployed to GitHub Pages, making `result.json` publicly accessible at `https://<YOUR_GITHUB_USERNAME>.github.io/<YOUR_REPOSITORY_NAME>/result.json`.

### `ci.yml` Content

```yaml
name: CI/CD Pipeline

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    permissions:
      contents: read
      pages: write
      id-token: write

    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas==2.3 ruff

      - name: Run Ruff Linter
        run: ruff check . --output-format=github

      - name: Convert data.xlsx to data.csv
        run: |
          python -c "import pandas as pd; df = pd.read_excel('data.xlsx'); df.to_csv('data.csv', index=False)"

      - name: Execute script and generate result.json
        run: python execute.py

      - name: Upload result.json artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: result.json

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
```

## Local Setup and Usage

To run this project locally, ensure you have Python 3.11+ installed.

1.  **Install dependencies**:
    ```bash
    pip install pandas==2.3 ruff
    ```

2.  **Convert `data.xlsx` to `data.csv`**:
    ```bash
    python -c "import pandas as pd; df = pd.read_excel('data.xlsx'); df.to_csv('data.csv', index=False)"
    ```

3.  **Run `execute.py`**:
    ```bash
    python execute.py
    ```
    This will generate `result.json` in your project directory.

4.  **Run Ruff Linter**:
    ```bash
    ruff check .
    ```

## License

This project is open-sourced under the MIT License. See the `LICENSE` file for full details.